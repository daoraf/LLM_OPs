from flask import Flask, render_template, request, jsonify
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
import os


app = Flask(__name__)

# ğŸ” Charger la clÃ© API OpenAI depuis les variables dâ€™environnement

load_dotenv()  # Charge les variables d'environnement du fichier .env

openai_api_key = os.getenv("OPENAI_API_KEY")

print(openai_api_key)
if not openai_api_key:
    raise ValueError("ğŸ”‘ ClÃ© API OpenAI manquante ! DÃ©finissez OPENAI_API_KEY dans vos variables dâ€™environnement.")

# ğŸ“¥ Charger la base de donnÃ©es vectorielle FAISS
def create_retriever(vector_db_path):
    embeddings = OpenAIEmbeddings()
    try:
        faiss_db = FAISS.load_local(vector_db_path, embeddings, allow_dangerous_deserialization=True)
        return faiss_db.as_retriever()
    except ValueError as e:
        print(f"âŒ Erreur lors du chargement de la base FAISS : {e}")
        return None

# ğŸ¤– CrÃ©ation du chatbot
def create_chatbot(vector_db_path):
    retriever = create_retriever(vector_db_path)
    if retriever is None:
        return None, None
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
    retrieval_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=retriever)
    return retrieval_chain, llm

# ğŸ­ Classe chatbot
class Chatbot:
    def __init__(self, vector_db_path):
        self.qa, self.llm = create_chatbot(vector_db_path)

    def ask(self, question):
        if not self.qa:
            return "âš ï¸ Erreur de chargement du modÃ¨le."
        # ğŸ” Recherche dans FAISS
        specific_response = self.qa.run(question)
        # ğŸ“Œ Si la rÃ©ponse est vide ou peu pertinente, utiliser GPT-3.5
        if not specific_response.strip():
            return self.llm.predict(question)
        return specific_response.strip()

# ğŸ¨ Interface Flask

vector_db_path = "C:\\Users\\daora\\IA_Naturalisation\\vectorstore"  # Adapte ce chemin

chatbot = Chatbot(vector_db_path)

chat_history = []

@app.route('/')
def home():
    return render_template('index.html', chat_history=chat_history)

@app.route('/ask', methods=['POST'])
def ask():
    global chat_history
    question = request.form['question']
    response = chatbot.ask(question)
    chat_history.append((question, response))
    return jsonify({"response": response, "chat_history": chat_history})

if __name__ == '__main__':
    app.run(host="0.0.0.0", port=8085, debug=True)

