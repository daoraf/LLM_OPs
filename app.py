import os
import chainlit as cl
import re
from datetime import datetime
from dotenv import load_dotenv
from langdetect import detect
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter

@cl.on_file
async def handle_file(file: cl.UploadedFile):
    try:
        if not file.name.endswith(".pdf"):
            await cl.Message(content="âŒ Seuls les fichiers PDF sont supportÃ©s pour le moment.").send()
            return

        # Lecture du contenu du fichier PDF
        pdf_reader = PdfReader(file.path)
        text = "\n".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])

        if not text.strip():
            await cl.Message(content="âŒ Aucun texte lisible trouvÃ© dans ce PDF.").send()
            return

        # Ajouter Ã  la base vectorielle
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectordb = FAISS.load_local("vectorstore", embeddings, allow_dangerous_deserialization=True)

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        text_with_meta = f"[{timestamp}] Contenu du document Â« {file.name} Â» :\n{text}"

        vectordb.add_texts([text_with_meta])
        vectordb.save_local("vectorstore")

        await cl.Message(content=f"ğŸ“„ Le document **{file.name}** a Ã©tÃ© ajoutÃ© Ã  la mÃ©moire. Posez vos questions Ã  son sujet !").send()

    except Exception as e:
        await cl.Message(content=f"âŒ Erreur lors du traitement du fichier : {e}").send()



# Charger la clÃ© API
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Charger la base FAISS existante
def load_vectorstore(path: str):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)

def create_qa_chain(vectorstore_path: str):
    db = load_vectorstore(vectorstore_path)
    retriever = db.as_retriever()
    llm = ChatOpenAI(model="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)
    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

qa_chain = create_qa_chain("vectorstore")

# Historique de conversation pour GPT
conversation_history = [
    {
        "role": "system",
        "content": (
            "Tu es un assistant expert en naturalisation franÃ§aise. "
            "Tes rÃ©ponses sont claires, bienveillantes et basÃ©es sur la loi. "
            "Tu rÃ©ponds dans la langue de l'utilisateur (franÃ§ais, anglais, espagnol, italien ou allemand). "
            "Si tu ne comprends pas la langue, utilise le franÃ§ais par dÃ©faut."
        )
    }
]

translations = {
    # ğŸ‡«ğŸ‡· FranÃ§ais
    "fr": {
        "welcome": "ğŸ‰ **Bienvenue dans l'Assistant de Naturalisation FranÃ§aise ğŸ‡«ğŸ‡·**\n\nJe suis lÃ  pour vous guider Ã  chaque Ã©tape du processus...",
        "guide_title": "ğŸ§­ **Guide Ã©tape par Ã©tape de la naturalisation**",
        "steps": [
            "ğŸ“ **Ã‰tape 1 :** Avez-vous plus de 18 ans...",
            "ğŸ“ **Ã‰tape 2 :** Votre casier judiciaire est-il compatible...",
            "ğŸ“ **Ã‰tape 3 :** Avez-vous une preuve de niveau de langue B1...",
            "ğŸ“ **Ã‰tape 4 :** Disposez-vous des documents administratifs nÃ©cessaires...",
            "ğŸ“ **Ã‰tape 5 :** Savez-vous comment et oÃ¹ dÃ©poser votre demande..."
        ],
        "checklist_prompt": "âœ… Si vous avez validÃ© toutes ces Ã©tapes, tapez `checklist`...",
        "checklist": """ğŸ“‹ **Checklist des documents Ã  fournir :**\n\n1. ğŸ›‚ Titre de sÃ©jour...\n2. ğŸ“„ Acte de naissance...\n...""",
        "depot": """ğŸ“¬ **DÃ©pÃ´t de votre demande :**\n\nVous pouvez dÃ©poser votre demande en ligne ou en prÃ©fecture..."""
    },

    # ğŸ‡¬ğŸ‡§ English
    "en": {
        "welcome": "ğŸ‰ **Welcome to the French Naturalization Assistant ğŸ‡«ğŸ‡·**\n\nI'm here to guide you...",
        "guide_title": "ğŸ§­ **Step-by-step naturalization guide**",
        "steps": [
            "ğŸ“ **Step 1:** Are you over 18...",
            "ğŸ“ **Step 2:** Is your criminal record clean?",
            "ğŸ“ **Step 3:** Do you have a B1 French certificate?",
            "ğŸ“ **Step 4:** Do you have required administrative documents?",
            "ğŸ“ **Step 5:** Do you know how and where to submit?"
        ],
        "checklist_prompt": "âœ… If you meet all the steps, type `checklist`...",
        "checklist": """ğŸ“‹ **Required documents checklist:**\n\n1. ğŸ›‚ Valid residence permit\n2. ğŸ“„ Birth certificate...\n...""",
        "depot": """ğŸ“¬ **Submitting your application:**\n\nYou can submit it online or at the prefecture..."""
    },

    # ğŸ‡ªğŸ‡¸ EspaÃ±ol
    "es": {
        "welcome": "ğŸ‰ **Bienvenido al Asistente de NaturalizaciÃ³n Francesa ğŸ‡«ğŸ‡·**\n\nEstoy aquÃ­ para guiarte...",
        "guide_title": "ğŸ§­ **GuÃ­a paso a paso para la naturalizaciÃ³n**",
        "steps": [
            "ğŸ“ **Paso 1:** Â¿Tienes mÃ¡s de 18 aÃ±os y vives en Francia desde hace 5 aÃ±os?",
            "ğŸ“ **Paso 2:** Â¿Tu historial judicial es compatible?",
            "ğŸ“ **Paso 3:** Â¿Tienes un certificado de nivel B1 en francÃ©s?",
            "ğŸ“ **Paso 4:** Â¿Tienes los documentos requeridos?",
            "ğŸ“ **Paso 5:** Â¿Sabes dÃ³nde y cÃ³mo presentar tu solicitud?"
        ],
        "checklist_prompt": "âœ… Si cumples con todos los pasos, escribe `checklist`...",
        "checklist": """ğŸ“‹ **Lista de documentos requeridos:**\n\n1. ğŸ›‚ Permiso de residencia vÃ¡lido\n2. ğŸ“„ Acta de nacimiento...\n...""",
        "depot": """ğŸ“¬ **PresentaciÃ³n de tu solicitud:**\n\nPuedes hacerlo en lÃ­nea o en la prefectura..."""
    },

    # ğŸ‡®ğŸ‡¹ Italiano
    "it": {
        "welcome": "ğŸ‰ **Benvenuto nell'Assistente per la Naturalizzazione Francese ğŸ‡«ğŸ‡·**\n\nSono qui per aiutarti...",
        "guide_title": "ğŸ§­ **Guida passo dopo passo alla naturalizzazione**",
        "steps": [
            "ğŸ“ **Passaggio 1:** Hai piÃ¹ di 18 anni e vivi in Francia da almeno 5 anni?",
            "ğŸ“ **Passaggio 2:** Il tuo casellario giudiziale Ã¨ compatibile?",
            "ğŸ“ **Passaggio 3:** Hai una certificazione di livello B1 in francese?",
            "ğŸ“ **Passaggio 4:** Hai tutti i documenti richiesti?",
            "ğŸ“ **Passaggio 5:** Sai dove e come presentare la domanda?"
        ],
        "checklist_prompt": "âœ… Se hai completato tutti i passaggi, digita `checklist`...",
        "checklist": """ğŸ“‹ **Elenco dei documenti richiesti:**\n\n1. ğŸ›‚ Permesso di soggiorno valido\n2. ğŸ“„ Certificato di nascita...\n...""",
        "depot": """ğŸ“¬ **Presentazione della domanda:**\n\nPuoi farlo online o in prefettura..."""
    },

    # ğŸ‡©ğŸ‡ª Deutsch
    "de": {
        "welcome": "ğŸ‰ **Willkommen beim Assistenten fÃ¼r die franzÃ¶sische EinbÃ¼rgerung ğŸ‡«ğŸ‡·**\n\nIch begleite Sie durch den gesamten Prozess...",
        "guide_title": "ğŸ§­ **Schritt-fÃ¼r-Schritt-Anleitung zur EinbÃ¼rgerung**",
        "steps": [
            "ğŸ“ **Schritt 1:** Sind Sie Ã¼ber 18 Jahre alt und leben seit mindestens 5 Jahren in Frankreich?",
            "ğŸ“ **Schritt 2:** Ist Ihr Strafregister mit der EinbÃ¼rgerung vereinbar?",
            "ğŸ“ **Schritt 3:** Haben Sie ein B1-Sprachnachweis in FranzÃ¶sisch?",
            "ğŸ“ **Schritt 4:** Haben Sie alle erforderlichen Unterlagen?",
            "ğŸ“ **Schritt 5:** Wissen Sie, wie und wo Sie den Antrag einreichen?"
        ],
        "checklist_prompt": "âœ… Wenn Sie alle Schritte erfÃ¼llt haben, geben Sie `checklist` ein...",
        "checklist": """ğŸ“‹ **Checkliste der erforderlichen Unterlagen:**\n\n1. ğŸ›‚ GÃ¼ltiger Aufenthaltstitel\n2. ğŸ“„ Geburtsurkunde...\n...""",
        "depot": """ğŸ“¬ **Einreichung Ihres Antrags:**\n\nSie kÃ¶nnen den Antrag online oder in der PrÃ¤fektur einreichen..."""
    }
}

def detect_language(text):
    try:
        lang = detect(text)
        return lang if lang in translations else "fr"
    except:
        return "fr"

def t(lang, key):
    return translations.get(lang, translations["fr"]).get(key, "")

@cl.on_chat_start
async def start():
    msg = (
        translations["fr"]["welcome"] +
        "\n\nğŸ’¡ Tapez `guide`, `checklist`, ou `dÃ©pÃ´t` Ã  tout moment pour Ãªtre guidÃ©." +
        "\nğŸ“ Vous pouvez aussi **tÃ©lÃ©verser un document PDF** (ex: questionnaire, justificatif) pour que je le lise."
    )
    await cl.Message(content=msg).send()

@cl.on_message
async def handle_message(message: cl.Message):
    global conversation_history
    user_input = message.content.strip()
    lang = detect_language(user_input)

    if user_input.lower() == "guide":
        await launch_step_by_step_guide(lang)
        return
    elif user_input.lower() == "checklist":
        await send_checklist(lang)
        return
    elif user_input.lower() == "dÃ©pÃ´t":
        await send_depot_info(lang)
        return
    elif user_input.lower() in ["/reset", "reset"]:
        conversation_history.clear()
        await cl.Message(content="â™»ï¸ Conversation rÃ©initialisÃ©e. Posez votre question !").send()
        return
    elif user_input.lower() == "mÃ©moire":
        await show_bot_memory()
        return

    try:
        # RÃ©ponse principale
        result = qa_chain.invoke({"query": user_input})
        await cl.Message(content=result["result"]).send()

        # --- Analyse de la mÃ©moire Ã  apprendre ---
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, openai_api_key=OPENAI_API_KEY)
        analysis_prompt = f"""
Tu es un assistant spÃ©cialisÃ© en naturalisation franÃ§aise.

Analyse ce message utilisateur :
\"{user_input}\"

- S'il contient une information factuelle utile, rÃ©sume-la clairement en une phrase.
- Sinon, rÃ©ponds uniquement "NON".
"""
        analysis = llm.predict(analysis_prompt).strip()
        print(f"ğŸ§  Analyse du message : {analysis}")

        if analysis.upper() != "NON":
            embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
            vectordb = FAISS.load_local("vectorstore", embeddings, allow_dangerous_deserialization=True)

            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            text_with_timestamp = f"[{timestamp}] {analysis}"

            vectordb.add_texts([text_with_timestamp])
            vectordb.save_local("vectorstore")

            print(f"ğŸ“Œ Nouvelle mÃ©moire ajoutÃ©e : {text_with_timestamp}")

        print("ğŸ“ Chemin absolu du vectorstore :", os.path.abspath("vectorstore"))

    except Exception as e:
        await cl.Message(content=f"âŒ Erreur : {e}").send()

async def show_bot_memory():
    try:
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectordb = FAISS.load_local("vectorstore", embeddings, allow_dangerous_deserialization=True)
        all_memory = list(vectordb.docstore._dict.values())

        if not all_memory:
            await cl.Message(content="ğŸ¤” Le bot nâ€™a encore rien appris.").send()
            return

        # SÃ©parer les mÃ©moires avec timestamp
        new_memories = []
        old_memories = []

        for i, doc in enumerate(all_memory):
            content = doc.page_content.strip()
            match = re.match(r"\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]", content)
            if match:
                dt = datetime.strptime(match.group(1), "%Y-%m-%d %H:%M:%S")
                new_memories.append((dt, i, content))
            else:
                old_memories.append((i, content))

        # Trier les nouvelles mÃ©moires du plus rÃ©cent au plus ancien
        new_memories.sort(reverse=True)

        message_parts = []

        if new_memories:
            message_parts.append("**ğŸ†• DerniÃ¨res infos apprises par le bot :**\n")
            for dt, i, content in new_memories:
                message_parts.append(f"{i + 1} - {content}")
        else:
            message_parts.append("â„¹ï¸ Aucune nouvelle information mÃ©morisÃ©e par conversation.")

        if old_memories:
            message_parts.append("\n\n**ğŸ“š Contenus prÃ©chargÃ©s (documents) :**\n")
            for i, content in old_memories[:5]:  # limite dâ€™affichage pour Ã©viter surcharge
                message_parts.append(f"{i + 1} - {content[:200]}...")

        full_output = "\n".join(message_parts)
        await cl.Message(content=full_output[:4000]).send()

    except Exception as e:
        await cl.Message(content=f"âŒ Erreur lors de l'affichage de la mÃ©moire : {e}").send()

async def launch_step_by_step_guide(lang="fr"):
    await cl.Message(content=t(lang, "guide_title")).send()
    for step in t(lang, "steps"):
        await cl.Message(content=step).send()
    await cl.Message(content=t(lang, "checklist_prompt")).send()

async def send_checklist(lang="fr"):
    await cl.Message(content=t(lang, "checklist")).send()

async def send_depot_info(lang="fr"):
    await cl.Message(content=t(lang, "depot")).send()

async def handle_user_command(cmd: str, lang: str = "fr"):
    cmd = cmd.lower()
    if cmd == "guide":
        await launch_step_by_step_guide(lang)
    elif cmd == "checklist":
        await send_checklist(lang)
    elif cmd == "dÃ©pÃ´t":
        await send_depot_info(lang)
    elif cmd == "mÃ©moire":
        await show_bot_memory()


@cl.action_callback
async def on_action(action: cl.Action):
    await handle_user_command(action.value, "fr")


@cl.on_file
async def handle_file(file: cl.UploadedFile):
    try:
        if not file.name.endswith(".pdf"):
            await cl.Message(content="âŒ Seuls les fichiers PDF sont supportÃ©s pour le moment.").send()
            return

        # Lire le texte du PDF
        pdf_reader = PdfReader(file.path)
        text = "\n".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])

        if not text.strip():
            await cl.Message(content="âŒ Aucun texte lisible trouvÃ© dans ce PDF.").send()
            return

        # DÃ©couper le texte en petits morceaux intelligents
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,       # max chars par chunk
            chunk_overlap=100,    # chevauchement pour contexte
            separators=["\n\n", "\n", ".", " "]  # ordre des sÃ©parateurs
        )
        chunks = splitter.split_text(text)

        # Ajouter les chunks Ã  FAISS
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectordb = FAISS.load_local("vectorstore", embeddings, allow_dangerous_deserialization=True)

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        chunked_with_metadata = [f"[{timestamp}] (Doc: {file.name}) {chunk}" for chunk in chunks]

        vectordb.add_texts(chunked_with_metadata)
        vectordb.save_local("vectorstore")

        await cl.Message(content=f"âœ… Le document **{file.name}** a Ã©tÃ© dÃ©coupÃ© en {len(chunks)} parties et ajoutÃ© Ã  la mÃ©moire. Posez vos questions !").send()

    except Exception as e:
        await cl.Message(content=f"âŒ Erreur lors du traitement du fichier : {e}").send()
